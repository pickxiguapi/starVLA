# 参数要求： 写了可以不用，但是用了就一定不能错
action_dim: 7
action_model_type: DiT-B
data_root_dir: playground/Datasets/OXE_openvla
future_action_window_size: 15
logging_frequency: 10
gradient_clipping: 1.0
hf_token: HF_TOKEN
image_aug: true
is_debug: false
is_resume: false
load_all_data_for_training: true
past_action_window_size: 0
pretrained_checkpoint: null
repeated_diffusion_steps: 8
resume_epoch: null
resume_step: null
run_id: 0606_ftqwen_withoutprompt_bridge_rt_1_32gpus_lr_5e-5_qformer_36_37_rp
run_id_note: null
run_root_dir: results/Checkpoints
save_interval: 5000
seed: 42
trackers:
- jsonl
- wandb
use_ema: false
wandb_entity: jinhuiye
wandb_project: llavavla

vla:
  base_vlm: /mnt/petrelfs/yejinhui/Projects/llavavla/playground/Pretrained_models/Qwen2.5-VL-3B-Instruct
  data_mix: bridge_rt_1
  enable_gradient_checkpointing: true
  enable_mixed_precision_training: true
  epochs: 100
  expected_world_size: 32
  action_dim: 7
  freeze_llm_backbone: false
  freeze_modules: ''
  freeze_vision_backbone: false
  pretrained_checkpoint: /mnt/petrelfs/yejinhui/Projects/llavavla/results/Checkpoints/0_bar/0601_qwenact_fixqwen_32gpus_lr_1e-3_qformer_36_37/steps_100000/pytorch_model.pt
  reload_modules: 'action_model,layer_qformer'
  global_batch_size: 512
  learning_rate: 5.0e-05
  lr_scheduler_type: constant
  max_grad_norm: 1.0
  max_steps: 100000
  per_device_batch_size: 16
  qformer_end_layer: 37
  qformer_start_layer: 36
  reduce_in_full_precision: true
  shuffle_buffer_size: 250000
  train_strategy: fsdp-full-shard
  type: prism-dinosiglip-224px+oxe+diffusion
  unfreeze_last_llm_layer: false
  vla_id: prism-dinosiglip-224px+oxe+diffusion
  warmup_ratio: 0.0
  weight_decay: 0.0
  qwenvl:
    attn_implementation: flash_attention_2
  layer_qformer: # 似乎会影响学习
    grad_scale: 0.5 # 让梯度经过这个模块的时候进行衰减，避免破坏VLM

trainer:
  learning_rate:
    base: 5.0e-05
    # qwen_vl_interface: 1.0e-05
    # action_model: 1.0e-04
  loss_scale:
    vla: 1.0
    vlm: 0.1


vlm_data:
  dataset_use: asv2_conversation_en,asv2_detailed_description_en,asv2_region_captioning_en,coco_internvl_longcap_en,coco_karpathy_train_567_en,coco_negative_gpt4o_en,coco_poetry_zh,coco_rem_en_zh,cocorem_exist_yorn_en,cocotextv2_en,cocotextv2_gpt4o_en,okvqa_en,refcoco_grounding_aug_en,refcoco_grounding_en,tallyqa_coco_en,toloka_grounding_aug_en,vqav2_en,vsr_en
  eval_dataset: aokvqa_cauldron_llava_format
  data_flatten: false
  base_interval: 2
  max_pixels: 50176
  min_pixels: 784
  fix_image_size: [224, 224]
  model_max_length: 1024 # 似乎这里必须是4096， 有些相互关联的内容并没有处理到
  model_type: qwen2.5vl
  per_device_batch_size: 4
  

