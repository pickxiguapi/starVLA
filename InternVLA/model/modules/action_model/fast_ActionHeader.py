"""Fast Action Tokenizer Adapter
"this file is adap from https://huggingface.co/physical-intelligence/fast"

æ¦‚è¿°:
    æœ¬æ¨¡å—å°è£…äº†ä¸€ä¸ªè½»é‡çº§â€œåŠ¨ä½œ â†’ è¯­è¨€æ¨¡å‹å¯è¯»åºåˆ—â€è½¬æ¢å™¨ (Fast_Action_Tokenizer)ã€‚
    å…¶æ ¸å¿ƒç›®æ ‡æ˜¯ï¼šæŠŠè¿ç»­ / ç¦»æ•£çš„åŸå§‹æœºå™¨äººåŠ¨ä½œï¼ˆraw_actionsï¼‰è½¬æ¢ä¸º
    å½¢å¦‚ <robot_action_12><robot_action_3><robot_action_87> ... çš„ä¼ªè‡ªç„¶è¯­è¨€ token ä¸²ï¼Œ
    ä¾¿äºç›´æ¥æ‹¼æ¥è¿›å¤šæ¨¡æ€å¤§æ¨¡å‹ (VLM / LLM) çš„å¯¹è¯æ¨¡æ¿ï¼Œå¤ç”¨å…¶è¯­è¨€å»ºæ¨¡èƒ½åŠ›è¿›è¡ŒåŠ¨ä½œé¢„æµ‹ã€‚
"""

import torch.nn as nn
from typing import List, Dict, Any, Callable, Optional
import os
import numpy as np
from transformers import AutoProcessor

from InternVLA.model.modules.vlm.QWen2_5 import _ACTION_TOKEN_MAX, _ACTION_TOKEN_MIN

class Fast_Action_Tokenizer(nn.Module):
    """One MLP ResNet block with a residual connection."""
    def __init__(self, fast_tokenizer_name="playground/Pretrained_models/fast"):
        super().__init__()
        
        self.fast_tokenizer = AutoProcessor.from_pretrained(
            fast_tokenizer_name, trust_remote_code=True
        )

        self._ACTION_TOKEN_MIN = _ACTION_TOKEN_MIN
        self._ACTION_TOKEN_MAX = _ACTION_TOKEN_MAX

    def encoder_action2vlmtoken(self, raw_actions):
        # x: (batch_size, chunck, dim)
        batch_actions = np.stack(raw_actions, axis=0)  # (B, T, D)
        batch_fast_tokens = self.fast_tokenizer(batch_actions)
        # batch_fast_tokens = [self.fast_tokenizer(raw_action)[0] for raw_action in raw_actions]
        batch_vlm_actions = [self.map_fast_token_to_vlm_action(fast_tokens) for fast_tokens in batch_fast_tokens]
        return batch_vlm_actions # List[str]
    
    def decoder_action(self, generated_ids):
        # api https://huggingface.co/physical-intelligence/fast
        # return: (batch_size, chunck, dim)
        pred_actions = self.fast_tokenizer.decode([generated_ids - self._ACTION_TOKEN_MIN])
        return pred_actions
    
    def map_fast_token_to_vlm_action(self, tokens) -> str:
        """Maps fast action tokens to the VLM action format.
        Action token 0 is mapped to the string <robot_action_0>  ... and so on 
        """
        return ''.join([f"<robot_action_{token}>" for token in tokens]) # you should add this to VLM as special tokens, 
        # and set the 
        #see /mnt/petrelfs/yejinhui/Projects/llavavla/InternVLA/model/modules/vlm/tools/add_qwen_special_tokens/README.md

    def fit_tokenizer_on_datasets(self, action_dataset, datasets_path="<your_local_path>", ):
        # å¦‚æœ datasets_path å­˜åœ¨ï¼Œ ç›´æ¥è¯»å–
        if os.path.exists(datasets_path):

            self.fast_tokenizer = AutoProcessor.from_pretrained(
            datasets_path, trust_remote_code=True
        )
            return
        else:
            # å¦‚æœä¸å­˜åœ¨ï¼ŒFit the tokenizer on the new dataset
            new_tokenizer = self.fast_tokenizer.tokenizer.fit(action_dataset)
            self.fast_tokenizer = new_tokenizer

            # Save the new tokenizer, optionally push it to the Hugging Face model hub
            self.fast_tokenizer.save_pretrained(datasets_path)


def get_action_model(config=None):
    """
    Factory: build ActionModel from global framework config.

    Args:
        config: Global config (expects config.framework.action_model namespace).
    Returns:
        ActionModel: Initialized diffusion action head.
    """
    action_model = Fast_Action_Tokenizer()

    return action_model


def start_debugpy_once():
    """start debugpy once"""
    import debugpy
    if getattr(start_debugpy_once, "_started", False):
        return
    debugpy.listen(("0.0.0.0", 10092))
    print("ğŸ” Waiting for VSCode attach on 0.0.0.0:10092 ...")
    debugpy.wait_for_client()
    start_debugpy_once._started = True

if __name__ == "__main__":

    start_debugpy_once()

    fast_tokenizer_name = "/mnt/petrelfs/yejinhui/Projects/llavavla/playground/Pretrained_models/fast"
    fast_tokenizer = Fast_Action_Tokenizer(fast_tokenizer_name=fast_tokenizer_name)
    raw_actions = [np.random.randn(16, 7), np.random.randn(16, 7)]

    # Load the tokenizer from the Hugging Face hub
    tokenizer = AutoProcessor.from_pretrained(fast_tokenizer_name, trust_remote_code=True)

    # basic test
    # Tokenize & decode action chunks (we use dummy data here)
    action_data = np.random.rand(2, 16, 7)    # one batch of action chunks
    tokens = tokenizer(action_data)              # tokens = list[int]
    decoded_actions = tokenizer.decode(tokens)

    # self func test
    vlm_tokens = fast_tokenizer.encoder_action2vlmtoken(raw_actions)
    print(vlm_tokens)
    pred_actions = fast_tokenizer.decoder_action(np.array([12,3,45,87]))
    print(pred_actions)





